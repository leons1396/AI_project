{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import colors\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Show the Image***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_plt(img_rgb):\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_image(img):\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***height (rows), width(cols)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_to_square(vegi_bgr):\n",
    "    img_size = 256\n",
    "    height, width = vegi_bgr.shape[:2]\n",
    "    a1 = width / height\n",
    "    a2 = height / width\n",
    "\n",
    "    if (a1 > a2):\n",
    "        r_img = cv2.resize(vegi_bgr, (round(img_size * a1), img_size), interpolation = cv2.INTER_AREA)\n",
    "        margin = int(r_img.shape[1]/6)\n",
    "        resized_img = r_img[0:img_size, margin:(margin+img_size)]\n",
    "\n",
    "    elif(a1 < a2):\n",
    "        # if height greater than width\n",
    "        r_img = cv2.resize(vegi_bgr, (img_size, round(img_size * a2)), interpolation = cv2.INTER_AREA)\n",
    "        margin = int(r_img.shape[0]/6)\n",
    "        resized_img = r_img[margin:(margin+img_size), 0:img_size]\n",
    "\n",
    "    elif(a1 == a2):\n",
    "        # if height and width are equal\n",
    "        r_img = cv2.resize(vegi_bgr, (img_size, round(img_size * a2)), interpolation = cv2.INTER_AREA)\n",
    "        resized_img = r_img[0:img_size, 0:img_size]\n",
    "\n",
    "    if(resized_img.shape[0] != img_size or resized_img.shape[1] != img_size):\n",
    "        resized_img = r_img[0:img_size, 0:img_size]\n",
    "\n",
    "    return resized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_color_values(img, shape_row=(0, 50), shape_col=(0, 60)):\n",
    "    for row in range(shape_row[0], shape_row[1]):\n",
    "        for col in range(shape_col[0], shape_col[1]):\n",
    "            print(f\"Row {row}: Spalte {col} Pixel: {img[row, col]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://realpython.com/python-opencv-color-spaces/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Code below is for data augmentation. It is a technique for enlarging a dataset.\n",
    "It will use the standard techniques like horizontal & vertical flipping and rotation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Images from personal cloud storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"G:\\Meine Ablage\\Images_AI_Project\\zwiebel_jpg\\zwiebel_1.jpg\"\n",
    "onion = cv2.imread(path.replace(\"\\\\\",\"/\"))\n",
    "#onion = cv2.cvtColor(onion, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "path = \"G:\\Meine Ablage\\KI_Projekt\\Bilder\\Karotte\\karotte_107.jpg\"\n",
    "carrot = cv2.imread(path.replace(\"\\\\\",\"/\"))\n",
    "#carrot = cv2.cvtColor(carrot, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "path = \"G:\\Meine Ablage\\KI_Projekt\\Bilder\\Karotte_Trieb\\karotte_trieb_67.jpg\"\n",
    "carrot_trieb = cv2.imread(path.replace(\"\\\\\",\"/\"))\n",
    "#carrot_trieb = cv2.cvtColor(carrot_trieb, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "path = \"G:\\Meine Ablage\\Images_AI_Project\\kartoffel_jpg\\kartoffel_122.jpg\"\n",
    "potato = cv2.imread(path.replace(\"\\\\\",\"/\"))\n",
    "#potato = cv2.cvtColor(potato, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "onion_sq = resize_to_square(onion)\n",
    "carrot_sq = resize_to_square(carrot)\n",
    "potato_sq = resize_to_square(potato)\n",
    "carrot_trieb_sq = resize_to_square(carrot_trieb)\n",
    "\n",
    "#show_image_plt(onion_sq)\n",
    "#show_image_plt(carrot_sq)\n",
    "#show_image_plt(potato_sq)\n",
    "#show_image_plt(carrot_trieb_sq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the median filter https://theailearner.com/tag/cv2-medianblur/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningknowledge.ai/image-segmentation-in-python-opencv/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.opencv.org/4.x/de/d62/tutorial_bounding_rotated_ellipses.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach: https://stackoverflow.com/questions/72100376/opencv-how-to-draw-a-rotated-bounding-box-in-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute dynamically thresholds: https://stackoverflow.com/questions/24862374/canny-edge-detector-threshold-values-gives-different-result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"G:\\Meine Ablage\\KI_Projekt\\Bilder\\Zwiebel\\zwiebel_9.jpg\"\n",
    "#vegi = cv2.imread(path.replace(\"\\\\\",\"/\")) # As BGR\n",
    "\n",
    "def draw_contours(bgr_img, object_area=500):\n",
    "    #gray = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2GRAY)\n",
    "    hsv = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    hue, saturation, value = cv2.split(hsv)\n",
    "    \n",
    "    blurred_sat = cv2.GaussianBlur(saturation, (7, 7), 0)\n",
    "    #show_image_plt(blurred_sat)\n",
    "    # Thresh 50 - 100\n",
    "    # Or from 85 - 100 removes some more small edges\n",
    "    # Thresh from 120 only shows the edge from vegi: karotte_107.jpg\"\n",
    "    # Compute the thresh dynamically from the mean() value. \n",
    "    thresh = blurred_sat.mean()\n",
    "    # *****\n",
    "    std = blurred_sat.std()\n",
    "    thresh_low = thresh - std\n",
    "    thresh_high = thresh + std\n",
    "    # The factors were simply selected by testing the algoritm. Another approach could be to calculate the mean with the standard deviation -> Test it ???\n",
    "    #thresh_low = 0.3 * thresh \n",
    "    #thresh_high = 2 * thresh\n",
    "    \n",
    "    #print(f\"Thresh low: {thresh_low} and Thresh high: {thresh_high}\")\n",
    "    # The next four lines control how good the bounding box will fit\n",
    "    edges = cv2.Canny(blurred_sat, thresh_low, thresh_high)\n",
    "    #show_image_plt(edges)\n",
    "    kernel = np.ones((4, 4), np.uint8) # creates 4x4 Identity matrix\n",
    "\n",
    "    # To see the effect if changing kernel and iterations plot it. It seems if the value is to small than the probabillity is higher that the edge lines are not closed\n",
    "    dilate = cv2.dilate(edges, kernel, iterations=4) \n",
    "    #show_image_plt(dilate)\n",
    "\n",
    "    erode = cv2.erode(dilate, kernel, iterations=4)\n",
    "    #show_image_plt(erode)\n",
    "    #print(\"SHAPE: \", erode.shape)\n",
    "    contours, hierarchy = cv2.findContours(erode, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10] # ???\n",
    "   \n",
    "    bgr_img_copy = bgr_img.copy()\n",
    "    # Flag makes sure that there is a maximum of 1 box in each image. Assumption, the bounding box for the vegi is always the biggest\n",
    "    more_than_one_box = False\n",
    "    for i, contour in enumerate(contours):\n",
    "        \n",
    "        area = cv2.contourArea(contour)\n",
    "        if area >= object_area:\n",
    "            rect = cv2.minAreaRect(contour)\n",
    "            box = cv2.boxPoints(rect)\n",
    "            box = np.intp(box)\n",
    "            cv2.drawContours(bgr_img_copy, [box], 0, (0, 255, 0), 2)\n",
    "            \n",
    "            # Ellipse\n",
    "            ellipse = cv2.fitEllipse(contour)\n",
    "            cv2.ellipse(bgr_img_copy, ellipse, (255, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            perimeter = cv2.arcLength(contour, True)\n",
    "            circularity = (4 * np.pi * area) / (perimeter ** 2)\n",
    "            #print(f\"Perimeter: {perimeter}  /// Circularity: {circularity}\")\n",
    "            #print(\"Draw Contour\")\n",
    "            if i > 0:\n",
    "                # There are more than 2 boxes in the image\n",
    "                more_than_one_box = True\n",
    "    \n",
    "    rgb = cv2.cvtColor(bgr_img_copy, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    return rgb, more_than_one_box, box, rect\n",
    "\n",
    "def get_size_box(box):\n",
    "    x0 = box[0][0]\n",
    "    y0 = box[0][1]\n",
    "    x1 = box[1][0]\n",
    "    y1 = box[1][1]\n",
    "\n",
    "    x2 = box[2][0]\n",
    "    y2 = box[2][1]\n",
    "\n",
    "    l0_1 = round(((x0 - x1)**2 + (y0 - y1)**2)**0.5, 2)\n",
    "    l1_2 = round(((x1 - x2)**2 + (y1 - y2)**2)**0.5, 2)\n",
    "\n",
    "    w = min(l0_1, l1_2)\n",
    "    h = max(l0_1, l1_2)\n",
    "\n",
    "    return h, w\n",
    "\n",
    "def crop_minAreaRect(img_BGR, rect, h, w):\n",
    "    pic = img_BGR.copy()\n",
    "    # rotate img\n",
    "    angle = rect[2]\n",
    "    rows,cols = img_BGR.shape[0], img_BGR.shape[1]\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2),angle,1)\n",
    "    img_rot = cv2.warpAffine(img_BGR,M,(cols,rows))\n",
    "    #show_image_plt(img_rot)\n",
    "    \n",
    "    # rotate bounding box\n",
    "    rect0 = (rect[0], rect[1], 0.0) \n",
    "    box = cv2.boxPoints(rect0)\n",
    "    box = np.intp(box)\n",
    "    #print(\"BOX:\", box)\n",
    "    cv2.drawContours(img_rot, [box], 0, (255, 255, 255), 1) # white frame\n",
    "\n",
    "    #pts = np.int0(cv2.transform(np.array([box]), M))[0]    \n",
    "    #pts[pts < 0] = 0\n",
    "\n",
    "    #print(\"TRANSFORMED BOX: \", pts)\n",
    "    w_rect = int(rect[1][0])\n",
    "    h_rect = int(rect[1][1])\n",
    "\n",
    "    # crop\n",
    "    box = np.clip(box, a_min=0, a_max=None)\n",
    "\n",
    "    img_crop_BGR = img_rot[box[1][1]:box[1][1]+h_rect, box[1][0]:box[1][0]+w_rect]\n",
    "\n",
    "    #img_crop = img_rot[pts[1][1]:pts[0][1], \n",
    "    #                   pts[1][0]:pts[2][0]]#\n",
    "\n",
    "    return img_crop_BGR\n",
    "\n",
    "def is_box_rotated(box):\n",
    "    # If the box is not rotated then the top left corner should be the first element in box array\n",
    "    x0, y0 = box[0][0], box[0][1]\n",
    "    y1 = box[1][1]\n",
    "    x3 = box[3][0]\n",
    "    \n",
    "    if y0 == y1 and x0 == x3:\n",
    "        # box is not rotated\n",
    "        return False\n",
    "    # BOX IS ROTATED\n",
    "    return True\n",
    "\n",
    "def get_color(rgb_segment):\n",
    "    cropped_vegi_2D = rgb_segment.reshape((-1,3))\n",
    "    # convert to np.float32\n",
    "    cropped_vegi_2D = np.float32(cropped_vegi_2D)\n",
    "\n",
    "    # define criteria and apply kmeans()\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1)\n",
    "    ret, label, center = cv2.kmeans(cropped_vegi_2D, 2, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "    center = np.uint8(center)\n",
    "   \n",
    "    res = center[label.flatten()]\n",
    "    res2 = res.reshape((rgb_segment.shape))\n",
    "    \n",
    "    #returns center in rgb format\n",
    "    return center, ret, label\n",
    "\n",
    "def mask_green(cropped_vegi_seg_rgb, lower_thresh=(30, 175, 25), higher_thresh=(100, 255, 255)):\n",
    "    ## Convert to HSV\n",
    "    cropped_vegi_seg_hsv = cv2.cvtColor(cropped_vegi_seg_rgb, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    ## Mask of green (36,25,25) ~ (86, 255,255)\n",
    "    # mask = cv2.inRange(hsv, (36, 25, 25), (86, 255,255))\n",
    "    mask = cv2.inRange(cropped_vegi_seg_hsv, lower_thresh, higher_thresh)\n",
    "    \n",
    "    ## Slice the green\n",
    "    imask = mask>0\n",
    "    green_rgb = np.zeros_like(cropped_vegi_seg_rgb, np.uint8)\n",
    "    green_rgb[imask] = cropped_vegi_seg_rgb[imask]\n",
    "\n",
    "    return green_rgb, imask\n",
    "\n",
    "    #Image as BGR\n",
    "def segment_img_2(cropped_vegi_bgr):\n",
    "    #img must be BGR\n",
    "    gray = cv2.cvtColor(cropped_vegi_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    ret, thresh = cv2.threshold(gray, 0, 255,cv2.THRESH_BINARY_INV +cv2.THRESH_OTSU)\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    closing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE,kernel, iterations = 15)\n",
    "    bg = cv2.dilate(closing, kernel, iterations = 1)\n",
    "    dist_transform = cv2.distanceTransform(closing, cv2.DIST_L2, 0)\n",
    "    ret, fg = cv2.threshold(dist_transform, 0.02*dist_transform.max(), 255, 0)\n",
    "\n",
    "    return thresh\n",
    "\n",
    "def color_from_segmented_binary(seg_bin, cropped_vegi_bgr):\n",
    "    imask = seg_bin>0 #False / True array\n",
    "    segment = np.zeros_like(cropped_vegi_bgr, np.uint8)\n",
    "    segment[imask] = cropped_vegi_bgr[imask] #BGR\n",
    "\n",
    "    segment_rgb = cv2.cvtColor(segment, cv2.COLOR_BGR2RGB) #RGB\n",
    "\n",
    "    return segment_rgb\n",
    "\n",
    "def keep_object_remove_green(mask, cropped_vegi_seg_rgb):\n",
    "    inverted_mask = np.invert(mask)\n",
    "    inverted_green_rgb = np.zeros_like(cropped_vegi_seg_rgb, np.uint8)\n",
    "    inverted_green_rgb[inverted_mask] = cropped_vegi_seg_rgb[inverted_mask]\n",
    "    \n",
    "    return inverted_green_rgb\n",
    "\n",
    "def count_green_pixels(binary_green_mask):\n",
    "    #only count True boolean. These are my green pixels\n",
    "    return binary_green_mask.sum()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_color(only_green_rgb): # binary mask\n",
    "    #only_green_rgb =  cv2.cvtColor(only_green, cv2.COLOR_GRAY2RGB)\n",
    "    only_green_hsv =  cv2.cvtColor(only_green_rgb, cv2.COLOR_RGB2HSV)\n",
    "    plt.imshow(only_green_hsv)\n",
    "    plt.show()\n",
    "\n",
    "    h, s, v = cv2.split(only_green_hsv)\n",
    "    h_1d = h.flatten()\n",
    "    s_1d = s.flatten()\n",
    "    v_1d = v.flatten()\n",
    "\n",
    "    h_mean_counter = 0\n",
    "    v_mean_counter = 0\n",
    "    s_mean_counter = 0\n",
    "    sum_h = 0\n",
    "    sum_v = 0\n",
    "    sum_s = 0\n",
    "    for i in range(0, h_1d.shape[0]):\n",
    "        if h_1d[i] > 1:\n",
    "            sum_h += h_1d[i]\n",
    "            h_mean_counter += 1\n",
    "\n",
    "        if v_1d[i] > 1:\n",
    "            sum_v += v_1d[i]\n",
    "            v_mean_counter += 1\n",
    "\n",
    "        if s_1d[i] > 1:\n",
    "            sum_s += s_1d[i]\n",
    "            s_mean_counter += 1\n",
    "\n",
    "    mean_h = int(sum_h / h_mean_counter)\n",
    "    mean_v = int(sum_v / v_mean_counter)\n",
    "    mean_s = int(sum_s / s_mean_counter)\n",
    "\n",
    "    print(f\"H: {mean_h} / S: {mean_s} / V: {mean_v} \")\n",
    "    print(h_mean_counter, s_mean_counter, v_mean_counter)\n",
    "\n",
    "    hsv = [mean_h, mean_s, mean_v]\n",
    "    rgb = cv2.cvtColor( np.uint8([[hsv]] ), cv2.COLOR_HSV2RGB)[0][0]\n",
    "    print(\"RGB: \", rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load images from storage and pass them through the preprocessing pipeline. The individual steps are:<br>\n",
    "- Read Image as BGR Format<br>\n",
    "- Resize Image to square format<br>\n",
    "- Draw bounding box around the object in the image and convert it to RGB<br>\n",
    "- get Hight and Width from the bounding box<br>\n",
    "- check If the box is rotated and depending on that crop the area of the bounding box out of the image<br>\n",
    "- Do Object Segmentation on the cropped image and return the binary segmented img (mask)<br>\n",
    "- Get the segmented cropped RGB image<br>\n",
    "- Place a green mask on the segmented cropped RGB image and get only the green pixels<br>\n",
    "- Calculate the color from the segmented cropped RGB image with kmeans algorithm. Set k=2<br>\n",
    "- Write the desired features to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "trieb\n",
      "Trieb_karotte\n"
     ]
    }
   ],
   "source": [
    "paths = []\n",
    "for fold in folders:\n",
    "    lower = fold.lower()\n",
    "    for i in range(100, 101): #87, 91\n",
    "        paths.append(f\"G:/Meine Ablage/KI_Projekt/Bilder/{fold}/{lower}_{i}.jpg\")\n",
    "a = paths[0].split(\".\")\n",
    "b = a[0].split(\"_\")\n",
    "print(b[-1])\n",
    "print(b[-2])\n",
    "if b[]\n",
    "print(b[-3].replace(\"/\", \"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Hight  Width    R    G   B  green pixels  green onion pixels      Label  \\\n",
      "0    168     72  135  111  82             0                   0  Kartoffel   \n",
      "\n",
      "          Image  \n",
      "0  Kartoffel_40  \n",
      "   Hight  Width    R    G   B  green pixels  green onion pixels      Label  \\\n",
      "0    168     72  135  111  82             0                   0  Kartoffel   \n",
      "1    178     73  133  108  83             0                   0  Kartoffel   \n",
      "\n",
      "          Image  \n",
      "0  Kartoffel_40  \n",
      "1  Kartoffel_41  \n",
      "   Hight  Width    R    G   B  green pixels  green onion pixels      Label  \\\n",
      "0    168     72  135  111  82             0                   0  Kartoffel   \n",
      "1    178     73  133  108  83             0                   0  Kartoffel   \n",
      "2    200    159  125  102  78             0                   0  Kartoffel   \n",
      "\n",
      "          Image  \n",
      "0  Kartoffel_40  \n",
      "1  Kartoffel_41  \n",
      "2  Kartoffel_42  \n",
      "############# Error: local variable 'box' referenced before assignment\n",
      "############# Error: local variable 'box' referenced before assignment\n",
      "############# Error: local variable 'box' referenced before assignment\n",
      "############# Error: local variable 'box' referenced before assignment\n",
      "############# Error: local variable 'box' referenced before assignment\n"
     ]
    }
   ],
   "source": [
    "#paths = [f\"G:\\Meine Ablage\\KI_Projekt\\Bilder\\Zwiebel\\zwiebel_{i}.jpg\" for i in range(10, 133)]\n",
    "#paths = [f\"G:\\Meine Ablage\\Images_AI_Project\\kartoffel_jpg_2\\kartoffel_{i}.jpg\" for i in range(40, 50)]\n",
    "\n",
    "folders = [\"Kartoffel\", \"Karotte\", \"Zwiebel\", \"Karotte_Trieb\", \"Zwiebel_Trieb\"]\n",
    "#folders = [\"Karotte\", \"Zwiebel\"]\n",
    "#folders = [\"Karotte_Trieb\"]\n",
    "paths = []\n",
    "for fold in folders:\n",
    "    lower = fold.lower()\n",
    "    for i in range(40, 141): #87, 91\n",
    "        paths.append(f\"G:/Meine Ablage/KI_Projekt/Bilder/{fold}/{lower}_{i}.jpg\")\n",
    "\n",
    "vegis_df = pd.DataFrame(columns=[\"Hight\", \"Width\", \"R\", \"G\", \"B\", \"green pixels\", \"green onion pixels\", \"Label\", \"Image\"])\n",
    "debug_list = list()        \n",
    "center_points = np.array([0, 0, 0])\n",
    "for i, path in enumerate(paths):\n",
    "    #print(f\"++++++++++++++++++++NEW IMAGE +++++++++++++++++++++++\\n\")\n",
    "    vegi_label = path.split(\"/\")[4]\n",
    "    \n",
    "    #vegi_BGR = cv2.imread(path.replace(\"\\\\\",\"/\")) # As BGR\n",
    "    vegi_BGR = cv2.imread(path) # As BGR\n",
    "    vegi_sq_BGR_original = resize_to_square(vegi_BGR) # BGR\n",
    "    #show_image_plt(vegi_sq)\n",
    "    try:\n",
    "        vegi_with_box_rgb, more_than_one_box, box, rect = draw_contours(vegi_sq_BGR_original)\n",
    "        if more_than_one_box:\n",
    "            box_size = 500\n",
    "            while more_than_one_box:\n",
    "                #print(\"Increase Box Size by 250\")\n",
    "                box_size += 250\n",
    "                vegi_with_box_rgb, more_than_one_box, box, rect = draw_contours(vegi_sq_BGR_original, box_size)\n",
    "\n",
    "        #plt.imshow(vegi_with_box_rgb)\n",
    "        #plt.show()\n",
    "        h, w = [int(l) for l in get_size_box(box)]\n",
    "        #print(f\"Height: {h}. width: {w}\")\n",
    "\n",
    "        if not is_box_rotated(box):\n",
    "            #crop img directly\n",
    "            #print(\"CROP DIRECTLY\")\n",
    "            # the top left corner should be the first element in box array\n",
    "            cropped_vegi_BGR = vegi_sq_BGR_original[box[0][1]:box[0][1]+h, box[0][0]:box[0][0]+w]\n",
    "            \n",
    "        else:\n",
    "            cropped_vegi_BGR = crop_minAreaRect(vegi_sq_BGR_original, rect, h, w) #BGR\n",
    "    \n",
    "        cropped_segmented_binary = segment_img_2(cropped_vegi_BGR)\n",
    "        #show_image_plt(cropped_segmented_binary)\n",
    "        #print(\"Segment whole object\")\n",
    "        cropped_vegi_segmented_rgb = color_from_segmented_binary(cropped_segmented_binary, cropped_vegi_BGR) # center has rgb format\n",
    "        #show_image_plt(cropped_vegi_segmented_rgb)\n",
    "        #lower_thresh=(30, 105, 20), higher_thresh=(160, 255, 255) good default values.\n",
    "        vegi_only_green_rgb, green_mask = mask_green(cropped_vegi_segmented_rgb, lower_thresh=(27, 105, 20), higher_thresh=(120, 255, 255))\n",
    "        \n",
    "        vegi_only_onion_tribe_rgb, onion_tribe_mask = mask_green(cropped_vegi_segmented_rgb, lower_thresh=(25, 40, 20), higher_thresh=(60, 160, 255))\n",
    "        \n",
    "        #show_image_plt(green_mask)\n",
    "        # Keep object without\n",
    "        cropped_vegi_green_removed_rgb = keep_object_remove_green(green_mask, cropped_vegi_segmented_rgb)\n",
    "\n",
    "        amount_green_pixels = count_green_pixels(green_mask)\n",
    "        amount_green_pixels_onion_tribe = count_green_pixels(onion_tribe_mask)\n",
    "        #print(\"AMOUNT OF GREEN;: \", amount_green_pixels)\n",
    "        #print(\"THIS IS Green ############################\")\n",
    "        #plt.imshow(vegi_only_green_rgb)\n",
    "        #plt.show()\n",
    "\n",
    "        #plt.imshow(vegi_only_onion_tribe_rgb)\n",
    "        #plt.show()\n",
    "        center, ret, label = get_color(cropped_vegi_segmented_rgb) #Center = RGB\n",
    "        R, G, B = np.max(center, axis=0)\n",
    "        #print(\"Center K-Means Algorith: \", center)\n",
    "        #print(\"Center MAX: \", R, G, B)\n",
    "\n",
    "        #print(\"Green removed\")\n",
    "        #plt.imshow(cropped_vegi_green_removed_rgb)\n",
    "        #plt.show()\n",
    "        \n",
    "        #rgb_mean_color = calculate_object_color(cropped_vegi_green_removed_rgb)\n",
    "        #print(f\"Mean RGB COLOR: {rgb_mean_color}\\n\\n\\n\")\n",
    "\n",
    "        #center_points = np.vstack([center_points, rgb_mean_color])\n",
    "\n",
    "        #debug_list.append(amount_green_pixels)\n",
    "        a = path.split(\".\")\n",
    "        b = a[0].split(\"_\")\n",
    "        img_name = f\"{vegi_label}_{b[-1]}\"\n",
    "        vegis_df.loc[len(vegis_df)] = [h, w, R, G, B, amount_green_pixels, amount_green_pixels_onion_tribe, vegi_label, img_name]\n",
    "        \n",
    "        if i < 3:\n",
    "            print(vegis_df)\n",
    "        #debug_color(vegi_only_green_rgb)\n",
    "\n",
    "        #cv2.imwrite(f\"G:\\Meine Ablage\\KI_Projekt\\Bilder\\BildermitBounding\\green_mask_test\\only_green_carrot\\{vegi_label}_{b[-1]}.jpg\", cv2.cvtColor(vegi_only_green_rgb, cv2.COLOR_BGR2RGB))\n",
    "        #cv2.imwrite(f\"G:\\Meine Ablage\\KI_Projekt\\Bilder\\BildermitBounding\\green_mask_test\\only_green_onion\\{vegi_label}_{b[-1]}.jpg\", cv2.cvtColor(vegi_only_onion_tribe_rgb, cv2.COLOR_BGR2RGB))\n",
    "        #cv2.imwrite(f\"G:\\Meine Ablage\\KI_Projekt\\Bilder\\BildermitBounding\\green_mask_test\\segmented_rgb\\{vegi_label}_{b[-1]}.jpg\", cv2.cvtColor(cropped_vegi_segmented_rgb, cv2.COLOR_BGR2RGB))\n",
    "    except Exception as e:\n",
    "        print(f\"############# Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vegis_df.to_csv(\"G:/Meine Ablage/KI_Projekt/Daten/green_mask_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_color(vegi_only_green_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 9)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vegis_df.head()\n",
    "vegis_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#cropped_vegi_green_removed_rgb\n",
    "cropped_vegi_segmented_hsv = cv2.cvtColor(cropped_vegi_segmented_rgb, cv2.COLOR_RGB2HSV)\n",
    "#cv2.imshow(\"Hsv\", cropped_vegi_green_removed_rgb)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "plt.imshow(cropped_vegi_green_removed_rgb)\n",
    "plt.show()\n",
    "for row in range(0, 20):\n",
    "    print(f\"++++++++++++ ROW {row}\")\n",
    "    for col in range(0, 110):\n",
    "        print(f\"{cropped_vegi_green_removed_rgb[row][col]}.  Col {col}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
