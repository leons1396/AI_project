{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import colors\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Show the Image***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_plt(img_bgr):\n",
    "    rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(rgb)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_image(img):\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***height (rows), width(cols)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(vegi):\n",
    "    height, width, c = vegi.shape\n",
    "    new_height = 100\n",
    "    ratio = new_height / height \n",
    "    new_width = int(width * ratio)\n",
    "    dimensions = (new_width, new_height)\n",
    "    print(dimensions)\n",
    "    resized_img = cv2.resize(vegi, dimensions, interpolation=cv2.INTER_LINEAR)\n",
    "    print(\"New shape:      \", resized_img.shape)\n",
    "\n",
    "    return resized_img\n",
    "\n",
    "# current values for borders they roughly fit to the real hsv values. I test it for brown onion, carrot, brown potato with\n",
    "# white background, respectively\n",
    "def mask_image(img_hsv, img_rgb, border_low=(8, 50, 75), border_high=(15, 255, 160)):\n",
    "    #15, 23, 135\n",
    "    mask = cv2.inRange(img_hsv, border_low, border_high)\n",
    "    result = cv2.bitwise_and(img_rgb, img_rgb, mask=mask)\n",
    "\n",
    "    #plt.subplot(1, 3, 1)\n",
    "    #plt.imshow(img_rgb)\n",
    "    #plt.subplot(1, 3, 2)\n",
    "    #plt.imshow(mask, cmap='gray')\n",
    "    #plt.subplot(1, 3, 3)\n",
    "    #plt.imshow(result)\n",
    "    #plt.show()\n",
    "    return mask, result\n",
    "    \n",
    "\n",
    "def resize_to_square(vegi_bgr):\n",
    "    img_size = 256\n",
    "    height, width = vegi_bgr.shape[:2]\n",
    "    a1 = width / height\n",
    "    a2 = height / width\n",
    "\n",
    "    if (a1 > a2):\n",
    "        r_img = cv2.resize(vegi_bgr, (round(img_size * a1), img_size), interpolation = cv2.INTER_AREA)\n",
    "        margin = int(r_img.shape[1]/6)\n",
    "        resized_img = r_img[0:img_size, margin:(margin+img_size)]\n",
    "\n",
    "    elif(a1 < a2):\n",
    "        # if height greater than width\n",
    "        r_img = cv2.resize(vegi_bgr, (img_size, round(img_size * a2)), interpolation = cv2.INTER_AREA)\n",
    "        margin = int(r_img.shape[0]/6)\n",
    "        resized_img = r_img[margin:(margin+img_size), 0:img_size]\n",
    "\n",
    "    elif(a1 == a2):\n",
    "        # if height and width are equal\n",
    "        r_img = cv2.resize(vegi_bgr, (img_size, round(img_size * a2)), interpolation = cv2.INTER_AREA)\n",
    "        resized_img = r_img[0:img_size, 0:img_size]\n",
    "\n",
    "    if(resized_img.shape[0] != img_size or resized_img.shape[1] != img_size):\n",
    "        resized_img = r_img[0:img_size, 0:img_size]\n",
    "\n",
    "    return resized_img\n",
    "\n",
    "\n",
    "def flip_image_and_show(img):\n",
    "    # flip vertical\n",
    "    img_v = cv2.flip(img, 0)\n",
    "    #show_image_plt(onion_sq_v)\n",
    "\n",
    "    #flip horizontal\n",
    "    img_h = cv2.flip(img, 1)\n",
    "    #show_image_plt(onion_sq_h)\n",
    "\n",
    "    #flip vertical + horizontal\n",
    "    img_vh = cv2.flip(img, -1)\n",
    "    #show_image_plt(onion_sq_vh)\n",
    "\n",
    "    fig, axarr = plt.subplots(2, 2) #1 row, 3 cols\n",
    "    fig.tight_layout(h_pad=4)\n",
    "    axarr[0][0].imshow(img)\n",
    "    axarr[0][0].set_title(\"Original\")\n",
    "    axarr[0][1].imshow(img_v)\n",
    "    axarr[0][1].set_title(\"Flip Vertical\")\n",
    "    axarr[1][0].imshow(img_h)\n",
    "    axarr[1][0].set_title(\"Flip Horizontal\")\n",
    "    axarr[1][1].imshow(img_vh)\n",
    "    axarr[1][1].set_title(\"Flip Vertical + Horizontal\")\n",
    "    fig.suptitle('Flipped Images')\n",
    "    plt.subplots_adjust(top = 0.85)\n",
    "\n",
    "\n",
    "def rotate_image_and_show(img):\n",
    "    # rotate 90 degree clockwise\n",
    "    img_r90 = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "    #show_image_plt(onion_sq_v)\n",
    "\n",
    "    #rotate 180 degree\n",
    "    img_r180 = cv2.rotate(img, cv2.ROTATE_180)\n",
    "    #show_image_plt(onion_sq_h)\n",
    "\n",
    "    #rotate 90 degree counterclockwise\n",
    "    img_rcw90 = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    #show_image_plt(onion_sq_vh)\n",
    "\n",
    "    fig, axarr = plt.subplots(2, 2) #2 row, 2 cols\n",
    "    fig.tight_layout(h_pad=4)\n",
    "\n",
    "    axarr[0][0].imshow(img)\n",
    "    axarr[0][0].set_title(\"Original\")\n",
    "    axarr[0][1].imshow(img_r90)\n",
    "    axarr[0][1].set_title(\"+ 90\")\n",
    "    axarr[1][0].imshow(img_r180)\n",
    "    axarr[1][0].set_title(\"+ 180\")\n",
    "    axarr[1][1].imshow(img_rcw90)\n",
    "    axarr[1][1].set_title(\"- 90\")\n",
    "\n",
    "    fig.suptitle('Rotated Images')\n",
    "    plt.subplots_adjust(top = 0.85)\n",
    "\n",
    "\n",
    "def draw_bounding_box(img, low_threshold, high_threshold):\n",
    "    # the thresholds are used as gradients thresholds. \n",
    "    # Something like, gradients smaller than the low_threshold or between the thresholds are ignored \n",
    "    result = img.copy()\n",
    "    gray_square_onion = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    thresh = cv2.threshold(gray_square_onion, low_threshold, high_threshold, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    # get contours\n",
    "    contours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "    for cntr in contours:\n",
    "        x,y,w,h = cv2.boundingRect(cntr)\n",
    "        # The idea is only keep bigger bounding boxes. Probably it presents the object\n",
    "        if w > 22 and h > 0.5:\n",
    "            cv2.rectangle(result, (x, y), (x+w, y+h), (100, 0, 255), 1)\n",
    "            ROI = img[y:y+h, x:x+w]\n",
    "            print(f\"ROI:. Size of Bounding Box: w = {w} / h = {h}\")\n",
    "        else:\n",
    "            continue\n",
    "    show_image_plt(result)\n",
    "\n",
    "\n",
    "def plot_color_space_rgb_to_hsv(img_rgb, convert_to_hsv=True):\n",
    "    copy_rgb = img_rgb.copy()\n",
    "    img_hsv = copy_rgb\n",
    "    x_label = \"R (X)\"\n",
    "    y_label = \"G (Y)\"\n",
    "    z_label = \"B (Z)\"\n",
    "\n",
    "    if convert_to_hsv:\n",
    "        img_hsv = cv2.cvtColor(copy_rgb, cv2.COLOR_RGB2HSV)\n",
    "        x_label = \"Hue X\"\n",
    "        y_label = \"Saturation Y\"\n",
    "        z_label = \"Value Z\"\n",
    "\n",
    "    pixel_colors = copy_rgb.reshape((np.shape(copy_rgb)[0]*np.shape(copy_rgb)[1], 3))\n",
    "    norm = colors.Normalize(vmin=-1.,vmax=1.)\n",
    "    norm.autoscale(pixel_colors)\n",
    "    pixel_colors = norm(pixel_colors).tolist()\n",
    "\n",
    "    x, y, z = cv2.split(img_hsv)\n",
    "    fig = plt.figure()\n",
    "    axis = fig.add_subplot(1, 1, 1, projection=\"3d\")\n",
    "\n",
    "    axis.scatter(x.flatten(), y.flatten(), z.flatten(), facecolors=pixel_colors, marker=\".\")\n",
    "    axis.set_xlabel(x_label)\n",
    "    axis.set_ylabel(y_label)\n",
    "    axis.set_zlabel(z_label)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def print_color_values(img):\n",
    "    for row in range(0, img.shape[1]):\n",
    "        for col in range(0, img.shape[1]):\n",
    "            print(f\"Row {row}: Spalte {col} {img[row, col]}\")\n",
    "\n",
    "def kMeans_(img_rgb, number_of_clusters, attempts):\n",
    "    # KMeans Processing\n",
    "    img_hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)\n",
    "    K = number_of_clusters\n",
    "    onion_2D = img_hsv.reshape((-1,3)) #Reshape to 2 dimensional image (65536, 3)\n",
    "    onion_2D = np.float32(onion_2D)\n",
    "\n",
    "    CONSTANT_1 = 10\n",
    "    CONSTANT_2 = 1.0\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, CONSTANT_1, CONSTANT_2)\n",
    "\n",
    "    ret, label, center=cv2.kmeans(onion_2D, K, None, criteria, attempts, cv2.KMEANS_PP_CENTERS)\n",
    "    center = np.uint8(center)\n",
    "    res = center[label.flatten()]\n",
    "    result_image = res.reshape((img_rgb.shape))\n",
    "\n",
    "    return result_image, label, center\n",
    "\n",
    "#Expect gray img\n",
    "def min_area_rect(img_rgb, low_thresh, high_thresh):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
    "    #gray = img_rgb.copy()\n",
    "    #gray = cv2.blur(gray, (3,3))\n",
    "\n",
    "    #plt.imshow(gray, cmap='gray')\n",
    "    #plt.show()\n",
    "\n",
    "    # Use Otsu's method to calculate a dynamic threshold\n",
    "    #a, thresh = cv2.threshold(gray, low_thresh, high_thresh, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    #print(thresh.min(), thresh.max())\n",
    "    #thresh_low = 0.5 * thresh\n",
    "    #thresh_high = 1.5 * thresh\n",
    "    # Apply edge detection using the dynamic threshold\n",
    "    edges = cv2.Canny(gray, low_thresh, high_thresh)\n",
    "    \n",
    "    # Find contours in the edged image\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    print('Length Contours: ', len(contours))\n",
    "    # Find the contour with the maximum area\n",
    "    max_contour = max(contours, key=cv2.contourArea)\n",
    "    #print(contours)\n",
    "    # Get the rotated bounding box of the contour\n",
    "    rect = cv2.minAreaRect(max_contour)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.intp(box)\n",
    "    \n",
    "    # Draw the rotated bounding box on the original image\n",
    "    result_image = img_rgb.copy()\n",
    "    cv2.drawContours(result_image, [box], 0, (0, 255, 0), 2)\n",
    "    thres = 10\n",
    "    return result_image, thres, box\n",
    "\n",
    "def get_object_color(center, cluster_img_hsv):\n",
    "    for point in center:\n",
    "        edge_point = 0\n",
    "        if (point == cluster_img_hsv[0][0]).all():\n",
    "            edge_point += 1\n",
    "\n",
    "        if (point == cluster_img_hsv[0][255]).all():\n",
    "            edge_point += 1\n",
    "\n",
    "        if (point == cluster_img_hsv[255][255]).all():\n",
    "            edge_point += 1\n",
    "\n",
    "        if (point == cluster_img_hsv[255][0]).all():\n",
    "            edge_point += 1\n",
    "\n",
    "        if edge_point >= 3:\n",
    "            #print(f\"Color Background found: {point}\")\n",
    "            pass\n",
    "\n",
    "        if edge_point < 3:\n",
    "            #print(f\"Color Object found: {point}\")\n",
    "            return point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://realpython.com/python-opencv-color-spaces/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Code below is for data augmentation. It is a technique for enlarging a dataset.\n",
    "It will use the standard techniques like horizontal & vertical flipping and rotation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Images from personal cloud storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"G:\\Meine Ablage\\Images_AI_Project\\zwiebel_jpg\\zwiebel_1.jpg\"\n",
    "onion = cv2.imread(path.replace(\"\\\\\",\"/\"))\n",
    "#onion = cv2.cvtColor(onion, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "path = \"G:\\Meine Ablage\\KI_Projekt\\Bilder\\Karotte\\karotte_107.jpg\"\n",
    "carrot = cv2.imread(path.replace(\"\\\\\",\"/\"))\n",
    "#carrot = cv2.cvtColor(carrot, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "path = \"G:\\Meine Ablage\\KI_Projekt\\Bilder\\Karotte_Trieb\\karotte_trieb_67.jpg\"\n",
    "carrot_trieb = cv2.imread(path.replace(\"\\\\\",\"/\"))\n",
    "#carrot_trieb = cv2.cvtColor(carrot_trieb, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "path = \"G:\\Meine Ablage\\Images_AI_Project\\kartoffel_jpg\\kartoffel_122.jpg\"\n",
    "potato = cv2.imread(path.replace(\"\\\\\",\"/\"))\n",
    "#potato = cv2.cvtColor(potato, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "onion_sq = resize_to_square(onion)\n",
    "carrot_sq = resize_to_square(carrot)\n",
    "potato_sq = resize_to_square(potato)\n",
    "carrot_trieb_sq = resize_to_square(carrot_trieb)\n",
    "\n",
    "show_image_plt(onion_sq)\n",
    "show_image_plt(carrot_sq)\n",
    "show_image_plt(potato_sq)\n",
    "show_image_plt(carrot_trieb_sq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the median filter https://theailearner.com/tag/cv2-medianblur/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningknowledge.ai/image-segmentation-in-python-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kMeans_for_rgb_img(img_rgb, number_of_clusters, attempts):\n",
    "    # KMeans Processing\n",
    "    #img_hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)\n",
    "    K = number_of_clusters\n",
    "    onion_2D = img_rgb.reshape((-1,3)) #Reshape to 2 dimensional image (65536, 3)\n",
    "    onion_2D = np.float32(onion_2D)\n",
    "\n",
    "    CONSTANT_1 = 10\n",
    "    CONSTANT_2 = 1.0\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, CONSTANT_1, CONSTANT_2)\n",
    "\n",
    "    ret, label, center=cv2.kmeans(onion_2D, K, None, criteria, attempts, cv2.KMEANS_PP_CENTERS)\n",
    "    center = np.uint8(center)\n",
    "    res = center[label.flatten()]\n",
    "    result_image = res.reshape((img_rgb.shape))\n",
    "\n",
    "    return result_image, label, center\n",
    "\n",
    "def mask_image_rgb(img_rgb, border_low=(8, 50, 75), border_high=(15, 255, 160)):\n",
    "    #15, 23, 135\n",
    "    mask = cv2.inRange(img_rgb, border_low, border_high)\n",
    "    result = cv2.bitwise_and(img_rgb, img_rgb, mask=mask)\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(mask, cmap='gray')\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(result)\n",
    "    plt.show()\n",
    "    return mask, result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kmeans_old(orig_img):\n",
    "    median_rgb = cv2.medianBlur(orig_img, 9)\n",
    "    show_image_plt(median_rgb)\n",
    "\n",
    "    #gaussian_onion = cv2.GaussianBlur(onion_sq,(5,5),0)\n",
    "    #show_image_plt(gaussian_onion)\n",
    "\n",
    "    clusterd_img_hsv, label, center = kMeans(median_rgb, number_of_clusters=2, attempts=100)\n",
    "    plt.imshow(clusterd_img_hsv)\n",
    "    plt.show()\n",
    "\n",
    "    return center, clusterd_img_hsv, median_rgb\n",
    "\n",
    "def run_bounding_box(clusterd_img_hsv, median_rgb, center_object, t_low, t_high):\n",
    "    masked_img_gray, masked_img_rgb = mask_image(clusterd_img_hsv, median_rgb, border_low=center_object, border_high=center_object) #borders for hsv colorspace\n",
    "    #print(masked_img_gray)\n",
    "    result_image, thresh, box = min_area_rect(masked_img_rgb, t_low, t_high)\n",
    "\n",
    "    plt.imshow(result_image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.opencv.org/4.x/de/d62/tutorial_bounding_rotated_ellipses.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach: https://stackoverflow.com/questions/72100376/opencv-how-to-draw-a-rotated-bounding-box-in-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute dynamically thresholds: https://stackoverflow.com/questions/24862374/canny-edge-detector-threshold-values-gives-different-result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"G:\\Meine Ablage\\KI_Projekt\\Bilder\\Zwiebel\\zwiebel_9.jpg\"\n",
    "#vegi = cv2.imread(path.replace(\"\\\\\",\"/\")) # As BGR\n",
    "\n",
    "def draw_contours(bgr_img, object_area=500):\n",
    "    #gray = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2GRAY)\n",
    "    hsv = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    hue, saturation, value = cv2.split(hsv)\n",
    "    \n",
    "    blurred_sat = cv2.GaussianBlur(saturation, (7, 7), 0)\n",
    "    #show_image_plt(blurred_sat)\n",
    "    # Thresh 50 - 100\n",
    "    # Or from 85 - 100 removes some more small edges\n",
    "    # Thresh from 120 only shows the edge from vegi: karotte_107.jpg\"\n",
    "    # Compute the thresh dynamically from the mean() value. \n",
    "    thresh = blurred_sat.mean()\n",
    "    # *****\n",
    "    std = blurred_sat.std()\n",
    "    thresh_low = thresh - std\n",
    "    thresh_high = thresh + std\n",
    "    # The factors were simply selected by testing the algoritm. Another approach could be to calculate the mean with the standard deviation -> Test it ???\n",
    "    #thresh_low = 0.3 * thresh \n",
    "    #thresh_high = 2 * thresh\n",
    "    \n",
    "    #print(f\"Thresh low: {thresh_low} and Thresh high: {thresh_high}\")\n",
    "    # The next four lines control how good the bounding box will fit\n",
    "    edges = cv2.Canny(blurred_sat, thresh_low, thresh_high)\n",
    "    #show_image_plt(edges)\n",
    "    kernel = np.ones((4, 4), np.uint8) # creates 4x4 Identity matrix\n",
    "\n",
    "    # To see the effect if changing kernel and iterations plot it. It seems if the value is to small than the probabillity is higher that the edge lines are not closed\n",
    "    dilate = cv2.dilate(edges, kernel, iterations=4) \n",
    "    #show_image_plt(dilate)\n",
    "\n",
    "    erode = cv2.erode(dilate, kernel, iterations=4)\n",
    "    #show_image_plt(erode)\n",
    "    #print(\"SHAPE: \", erode.shape)\n",
    "    contours, hierarchy = cv2.findContours(erode, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10] # ???\n",
    "   \n",
    "    bgr_img_copy = bgr_img.copy()\n",
    "    # Flag makes sure that there is a maximum of 1 box in each image. Assumption, the bounding box for the vegi is always the biggest\n",
    "    more_than_one_box = False\n",
    "    for i, contour in enumerate(contours):\n",
    "        \n",
    "        area = cv2.contourArea(contour)\n",
    "        if area >= object_area:\n",
    "            rect = cv2.minAreaRect(contour)\n",
    "            box = cv2.boxPoints(rect)\n",
    "            box = np.intp(box)\n",
    "            cv2.drawContours(bgr_img_copy, [box], 0, (0, 255, 0), 2)\n",
    "            \n",
    "            # Ellipse\n",
    "            ellipse = cv2.fitEllipse(contour)\n",
    "            cv2.ellipse(bgr_img_copy, ellipse, (255, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            perimeter = cv2.arcLength(contour, True)\n",
    "            circularity = (4 * np.pi * area) / (perimeter ** 2)\n",
    "            #print(f\"Perimeter: {perimeter}  /// Circularity: {circularity}\")\n",
    "            #print(\"Draw Contour\")\n",
    "            if i > 0:\n",
    "                # There are more than 2 boxes in the image\n",
    "                more_than_one_box = True\n",
    "    \n",
    "    rgb = cv2.cvtColor(bgr_img_copy, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    return rgb, more_than_one_box, box, rect\n",
    "\n",
    "def get_size_box(box):\n",
    "    x0 = box[0][0]\n",
    "    y0 = box[0][1]\n",
    "    x1 = box[1][0]\n",
    "    y1 = box[1][1]\n",
    "\n",
    "    x2 = box[2][0]\n",
    "    y2 = box[2][1]\n",
    "\n",
    "    l0_1 = round(((x0 - x1)**2 + (y0 - y1)**2)**0.5, 2)\n",
    "    l1_2 = round(((x1 - x2)**2 + (y1 - y2)**2)**0.5, 2)\n",
    "\n",
    "    w = min(l0_1, l1_2)\n",
    "    h = max(l0_1, l1_2)\n",
    "\n",
    "    return h, w\n",
    "\n",
    "def crop_minAreaRect(img_BGR, rect, h, w):\n",
    "    pic = img_BGR.copy()\n",
    "    # rotate img\n",
    "    angle = rect[2]\n",
    "    rows,cols = img_BGR.shape[0], img_BGR.shape[1]\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2),angle,1)\n",
    "    img_rot = cv2.warpAffine(img_BGR,M,(cols,rows))\n",
    "    #show_image_plt(img_rot)\n",
    "    \n",
    "    # rotate bounding box\n",
    "    rect0 = (rect[0], rect[1], 0.0) \n",
    "    box = cv2.boxPoints(rect0)\n",
    "    box = np.intp(box)\n",
    "    #print(\"BOX:\", box)\n",
    "    cv2.drawContours(img_rot, [box], 0, (255, 255, 255), 1) # white frame\n",
    "    #show_image_plt(img_rot)\n",
    "    #pts = np.int0(cv2.transform(np.array([box]), M))[0]    \n",
    "    #pts[pts < 0] = 0\n",
    "    #print(\"TRANSFORMED BOX: \", pts)\n",
    "    w_rect = int(rect[1][0])\n",
    "    h_rect = int(rect[1][1])\n",
    "    #print(f\"IN CROP from rect**: width: {w_rect} hight {h_rect}\")\n",
    "    # crop\n",
    "    box = np.clip(box, a_min=0, a_max=None)\n",
    "    #print(box)\n",
    "    img_crop_BGR = img_rot[box[1][1]:box[1][1]+h_rect, box[1][0]:box[1][0]+w_rect]\n",
    "\n",
    "    #img_crop = img_rot[pts[1][1]:pts[0][1], \n",
    "    #                   pts[1][0]:pts[2][0]]#\n",
    "\n",
    "    return img_crop_BGR\n",
    "\n",
    "def is_box_rotated(box):\n",
    "    # If the box is not rotated then the top left corner should be the first element in box array\n",
    "    x0, y0 = box[0][0], box[0][1]\n",
    "    y1 = box[1][1]\n",
    "    x3 = box[3][0]\n",
    "    \n",
    "    if y0 == y1 and x0 == x3:\n",
    "        # box is not rotated\n",
    "        return False\n",
    "    #print(\"BOX IS ROTATED\")\n",
    "    return True\n",
    "\n",
    "def get_color(rgb_segment):\n",
    "    cropped_vegi_2D = rgb_segment.reshape((-1,3))\n",
    "    # convert to np.float32\n",
    "    cropped_vegi_2D = np.float32(cropped_vegi_2D)\n",
    "\n",
    "    # define criteria and apply kmeans()\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1)\n",
    "    ret,label,center=cv2.kmeans(cropped_vegi_2D, 2, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    # Now separate the data, Note the flatten()\n",
    "    A = cropped_vegi_2D[label.ravel()==0]\n",
    "    B = cropped_vegi_2D[label.ravel()==1]\n",
    "\n",
    "    # Plot the data\n",
    "    #plt.scatter(A[:,0],A[:,1])\n",
    "    #plt.scatter(B[:,0],B[:,1],c = 'r')\n",
    "    #plt.scatter(center[:,0],center[:,1],s = 80,c = 'y', marker = 's')\n",
    "    #plt.xlabel('Height'),plt.ylabel('Weight')\n",
    "    #plt.show()\n",
    "\n",
    "    center = np.uint8(center)\n",
    "    #print(\"CENTERS: \", center)\n",
    "    res = center[label.flatten()]\n",
    "    res2 = res.reshape((rgb_segment.shape))\n",
    "    \n",
    "    #returns center in rgb format\n",
    "    return center, ret, label\n",
    "\n",
    "def mask_green(cropped_vegi_seg_rgb, lower_thresh=(30, 175, 25), higher_thresh=(100, 255, 255)):\n",
    "    ## Convert to HSV\n",
    "    cropped_vegi_seg_hsv = cv2.cvtColor(cropped_vegi_seg_rgb, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    ## Mask of green (36,25,25) ~ (86, 255,255)\n",
    "    # mask = cv2.inRange(hsv, (36, 25, 25), (86, 255,255))\n",
    "    mask = cv2.inRange(cropped_vegi_seg_hsv, lower_thresh, higher_thresh)\n",
    "\n",
    "    #plt.imshow(mask, cmap='gray')\n",
    "    #plt.show()\n",
    "    \n",
    "    ## Slice the green\n",
    "    imask = mask>0\n",
    "    green_rgb = np.zeros_like(cropped_vegi_seg_rgb, np.uint8)\n",
    "    green_rgb[imask] = cropped_vegi_seg_rgb[imask]\n",
    "\n",
    "    return green_rgb, imask\n",
    "\n",
    "    #Image as BGR\n",
    "def segment_img_2(cropped_vegi_bgr):\n",
    "    #img must be BGR\n",
    "    gray = cv2.cvtColor(cropped_vegi_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    ret, thresh = cv2.threshold(gray, 0, 255,cv2.THRESH_BINARY_INV +cv2.THRESH_OTSU)\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    closing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE,kernel, iterations = 15)\n",
    "    bg = cv2.dilate(closing, kernel, iterations = 1)\n",
    "    dist_transform = cv2.distanceTransform(closing, cv2.DIST_L2, 0)\n",
    "    ret, fg = cv2.threshold(dist_transform, 0.02*dist_transform.max(), 255, 0)\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10,10))\n",
    "    \n",
    "    plt.subplot(2,2,1)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(cropped_vegi, cmap=\"gray\")\n",
    "\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.imshow(gray, cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.title(\"GrayScale Image\")\n",
    "    \n",
    "    plt.subplot(2,2,3)\n",
    "    plt.imshow(thresh, cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Threshold Image\")\n",
    "\n",
    "    plt.subplot(2,2,4)\n",
    "    plt.imshow(fg, cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Segmented Image\")\n",
    "\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    return thresh\n",
    "\n",
    "def color_from_segmented_binary(seg_bin, cropped_vegi_bgr):\n",
    "    imask = seg_bin>0 #False / True array\n",
    "    segment = np.zeros_like(cropped_vegi_bgr, np.uint8)\n",
    "    segment[imask] = cropped_vegi_bgr[imask] #BGR\n",
    "\n",
    "    segment_rgb = cv2.cvtColor(segment, cv2.COLOR_BGR2RGB) #RGB\n",
    "\n",
    "    return segment_rgb\n",
    "\n",
    "def keep_object_remove_green(mask, cropped_vegi_seg_rgb):\n",
    "    inverted_mask = np.invert(mask)\n",
    "    inverted_green_rgb = np.zeros_like(cropped_vegi_seg_rgb, np.uint8)\n",
    "    inverted_green_rgb[inverted_mask] = cropped_vegi_seg_rgb[inverted_mask]\n",
    "    \n",
    "    return inverted_green_rgb\n",
    "\n",
    "def count_green_pixels(binary_green_mask):\n",
    "    #only count True boolean. These are my green pixels\n",
    "    return binary_green_mask.sum()\n",
    "    \n",
    "def calculate_object_color(vegi_without_green_rgb):\n",
    "    # Calculate mean color value in HSV Color Space\n",
    "    # Only keep pixels >(1,1,1) (black)\n",
    "    # Only keep pixel > (1, 100, 100)\n",
    "    # Only keep pixels < (255, 225, 225)\n",
    "    # Filter by Saturation and Value\n",
    "    vegi_without_green_hsv =  cv2.cvtColor(vegi_without_green_rgb, cv2.COLOR_RGB2HSV)\n",
    "    h, s, v = cv2.split(vegi_without_green_hsv)\n",
    "    h_1d = h.flatten()\n",
    "    s_1d = s.flatten()\n",
    "    v_1d = v.flatten()\n",
    "\n",
    "    h_mean_counter = 0\n",
    "    s_mean_counter = 0\n",
    "    v_mean_counter = 0\n",
    "    sum_h = 0\n",
    "    sum_s = 0\n",
    "    sum_v = 0\n",
    "    for i in range(0, h_1d.shape[0]):\n",
    "        if h_1d[i] > 1 and h_1d[i] < 250:\n",
    "            sum_h += h_1d[i]\n",
    "            h_mean_counter += 1\n",
    "\n",
    "        if s_1d[i] > 100 and s_1d[i] < 225:\n",
    "            sum_s += s_1d[i]\n",
    "            s_mean_counter += 1\n",
    "            sum_v += v_1d[i]\n",
    "            v_mean_counter += 1\n",
    "        #if v_1d[i] > 30 and v_1d[i] < 225:\n",
    "        #    sum_v += v_1d[i]\n",
    "        #    v_mean_counter += 1\n",
    "    \n",
    "    #Maybe catch exception if the incoming img has no object and because of that we devide by zero\n",
    "    mean_h = int(sum_h / h_mean_counter)\n",
    "    mean_s = int(sum_s / s_mean_counter)\n",
    "    mean_v = int(sum_v / v_mean_counter)\n",
    "    \n",
    "    #print(f\"H: {mean_h} / S: {mean_s} / V: {mean_v}\")\n",
    "    #print(f\"H Counter: {h_mean_counter} / S Counter: {s_mean_counter} / V Coutner: {v_mean_counter}\")\n",
    "\n",
    "    hsv_color = [mean_h, mean_s, mean_v]\n",
    "   \n",
    "    rgb_color = cv2.cvtColor(np.uint8([[hsv_color]]), cv2.COLOR_HSV2RGB)[0][0]\n",
    "    \n",
    "    return rgb_color\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[[4, 2, 3], [1, 2, 3], [7, 2, 3], [1, 6, 3],\n",
    "             [1, 20, 3], [8, 2, 3], [1, 3, -3], [10, 2, 99]],\n",
    "             [[1, 12, 3], [1, 2, 13], [1, 5, 3], [1, 2, 3],\n",
    "             [1, 22, 3], [1, 2, 3], [1, 2, 3], [-1, 2, -3]],\n",
    "             [[11, 2, 3], [1, 21, 3], [1, 2, 3], [1, 29, 3],\n",
    "             [1, 2, 3], [1, 8, 13], [-1, 2, -3], [1, 2, 3]]])\n",
    "\n",
    "def debug_color(only_green_rgb): # binary mask\n",
    "    #only_green_rgb =  cv2.cvtColor(only_green, cv2.COLOR_GRAY2RGB)\n",
    "    only_green_hsv =  cv2.cvtColor(only_green_rgb, cv2.COLOR_RGB2HSV)\n",
    "    plt.imshow(only_green_hsv)\n",
    "    plt.show()\n",
    "\n",
    "    h, s, v = cv2.split(only_green_hsv)\n",
    "    h_1d = h.flatten()\n",
    "    s_1d = s.flatten()\n",
    "    v_1d = v.flatten()\n",
    "\n",
    "    h_mean_counter = 0\n",
    "    v_mean_counter = 0\n",
    "    s_mean_counter = 0\n",
    "    sum_h = 0\n",
    "    sum_v = 0\n",
    "    sum_s = 0\n",
    "    for i in range(0, h_1d.shape[0]):\n",
    "        if h_1d[i] > 1:\n",
    "            sum_h += h_1d[i]\n",
    "            h_mean_counter += 1\n",
    "\n",
    "        if v_1d[i] > 1:\n",
    "            sum_v += v_1d[i]\n",
    "            v_mean_counter += 1\n",
    "\n",
    "        if s_1d[i] > 1:\n",
    "            sum_s += s_1d[i]\n",
    "            s_mean_counter += 1\n",
    "\n",
    "    mean_h = int(sum_h / h_mean_counter)\n",
    "    mean_v = int(sum_v / v_mean_counter)\n",
    "    mean_s = int(sum_s / s_mean_counter)\n",
    "\n",
    "    print(f\"H: {mean_h} / S: {mean_s} / V: {mean_v} \")\n",
    "    print(h_mean_counter, s_mean_counter, v_mean_counter)\n",
    "\n",
    "    hsv = [mean_h, mean_s, mean_v]\n",
    "    rgb = cv2.cvtColor( np.uint8([[hsv]] ), cv2.COLOR_HSV2RGB)[0][0]\n",
    "    print(\"RGB: \", rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths = [f\"G:\\Meine Ablage\\KI_Projekt\\Bilder\\Zwiebel\\zwiebel_{i}.jpg\" for i in range(10, 133)]\n",
    "#paths = [f\"G:\\Meine Ablage\\Images_AI_Project\\kartoffel_jpg_2\\kartoffel_{i}.jpg\" for i in range(40, 50)]\n",
    "\n",
    "#folders = [\"Kartoffel\", \"Karotte\", \"Zwiebel\", \"Karotte_Trieb\"]\n",
    "#folders = [\"Kartoffel\", \"Karotte\", \"Zwiebel\"]\n",
    "folders = [\"Zwiebel_Trieb\"]\n",
    "paths = []\n",
    "for fold in folders:\n",
    "    lower = fold.lower()\n",
    "    for i in range(32, 34): #87, 91\n",
    "        paths.append(f\"G:\\Meine Ablage\\KI_Projekt\\Bilder\\{fold}\\{lower}_{i}.jpg\")\n",
    "\n",
    "vegis_df = pd.DataFrame(columns=[\"Hight\", \"Width\", \"R\", \"G\", \"B\", \"green pixels\" ,\"Label\"])\n",
    "debug_list = list()        \n",
    "center_points = np.array([0, 0, 0])\n",
    "for i, path in enumerate(paths):\n",
    "    #print(f\"++++++++++++++++++++NEW IMAGE +++++++++++++++++++++++\\n\")\n",
    "    vegi_label = path.split(\"\\\\\")[4]\n",
    "    \n",
    "    vegi_BGR = cv2.imread(path.replace(\"\\\\\",\"/\")) # As BGR\n",
    "    vegi_sq_BGR_original = resize_to_square(vegi_BGR) # BGR\n",
    "    #show_image_plt(vegi_sq)\n",
    "    try:\n",
    "        vegi_with_box_rgb, more_than_one_box, box, rect = draw_contours(vegi_sq_BGR_original)\n",
    "        if more_than_one_box:\n",
    "            box_size = 500\n",
    "            while more_than_one_box:\n",
    "                #print(\"Increase Box Size by 250\")\n",
    "                box_size += 250\n",
    "                vegi_with_box_rgb, more_than_one_box, box, rect = draw_contours(vegi_sq_BGR_original, box_size)\n",
    "\n",
    "        plt.imshow(vegi_with_box_rgb)\n",
    "        plt.show()\n",
    "        h, w = [int(l) for l in get_size_box(box)]\n",
    "        #print(f\"Height: {h}. width: {w}\")\n",
    "\n",
    "        if not is_box_rotated(box):\n",
    "            #crop img directly\n",
    "            #print(\"CROP DIRECTLY\")\n",
    "            # the top left corner should be the first element in box array\n",
    "            cropped_vegi_BGR = vegi_sq_BGR_original[box[0][1]:box[0][1]+h, box[0][0]:box[0][0]+w]\n",
    "            \n",
    "        else:\n",
    "            cropped_vegi_BGR = crop_minAreaRect(vegi_sq_BGR_original, rect, h, w) #BGR\n",
    "        \n",
    "            \n",
    "        cropped_segmented_binary = segment_img_2(cropped_vegi_BGR)\n",
    "\n",
    "        #print(\"Segment whole object\")\n",
    "        cropped_vegi_segmented_rgb = color_from_segmented_binary(cropped_segmented_binary, cropped_vegi_BGR) # center has rgb format\n",
    "\n",
    "        #lower_thresh=(30, 105, 20), higher_thresh=(160, 255, 255) good default values.\n",
    "        vegi_only_green_rgb, green_mask = mask_green(cropped_vegi_segmented_rgb, lower_thresh=(30, 105, 20), higher_thresh=(140, 255, 255))\n",
    "        \n",
    "\n",
    "        # Keep object without\n",
    "        cropped_vegi_green_removed_rgb = keep_object_remove_green(green_mask, cropped_vegi_segmented_rgb)\n",
    "\n",
    "        amount_green_pixels = count_green_pixels(green_mask)\n",
    "        #print(\"AMOUNT OF GREEN;: \", amount_green_pixels)\n",
    "        print(\"THIS IS Green ############################\")\n",
    "        plt.imshow(vegi_only_green_rgb)\n",
    "        plt.show()\n",
    "\n",
    "        center, ret, label = get_color(cropped_vegi_segmented_rgb) #Center = RGB\n",
    "        R, G, B = np.max(center, axis=0)\n",
    "        #print(\"Center K-Means Algorith: \", center)\n",
    "        #print(\"Center MAX: \", R, G, B)\n",
    "\n",
    "        print(\"Green removed\")\n",
    "        plt.imshow(cropped_vegi_green_removed_rgb)\n",
    "        plt.show()\n",
    "        #rgb_mean_color = calculate_object_color(cropped_vegi_green_removed_rgb)\n",
    "        #print(f\"Mean RGB COLOR: {rgb_mean_color}\\n\\n\\n\")\n",
    "\n",
    "        #center_points = np.vstack([center_points, rgb_mean_color])\n",
    "\n",
    "        #debug_list.append(amount_green_pixels)\n",
    "\n",
    "        vegis_df.loc[len(vegis_df)] = [h, w, R, G, B, amount_green_pixels, vegi_label]\n",
    "        \n",
    "        if i < 3:\n",
    "            print(vegis_df)\n",
    "        #debug_color(vegi_only_green_rgb)\n",
    "        #cv2.imwrite(f\"G:\\Meine Ablage\\KI_Projekt\\Bilder\\BildermitBounding\\only_green_3\\img_{i}.jpg\", cv2.cvtColor(vegi_only_green_rgb, cv2.COLOR_BGR2RGB))\n",
    "        #cv2.imwrite(f\"G:\\Meine Ablage\\KI_Projekt\\Bilder\\BildermitBounding\\without_green_3\\img_{i}.jpg\", cv2.cvtColor(cropped_vegi_green_removed_rgb, cv2.COLOR_BGR2RGB))\n",
    "    except Exception as e:\n",
    "        print(f\"############# Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vegis_df.to_csv(\"G:/Meine Ablage/KI_Projekt/Daten/pot_car_onio_carTribe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_color(vegi_only_green_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#cropped_vegi_green_removed_rgb\n",
    "cropped_vegi_segmented_hsv = cv2.cvtColor(cropped_vegi_segmented_rgb, cv2.COLOR_RGB2HSV)\n",
    "#cv2.imshow(\"Hsv\", cropped_vegi_green_removed_rgb)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "plt.imshow(cropped_vegi_green_removed_rgb)\n",
    "plt.show()\n",
    "for row in range(0, 20):\n",
    "    print(f\"++++++++++++ ROW {row}\")\n",
    "    for col in range(0, 110):\n",
    "        print(f\"{cropped_vegi_green_removed_rgb[row][col]}.  Col {col}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"G:\\Meine Ablage\\KI_Projekt\\center_points\\center_array.npy\"\n",
    "# Save the array to a binary file\n",
    "np.save(file_path.replace(\"\\\\\",\"/\"), reshaped_array_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"G:\\Meine Ablage\\KI_Projekt\\center_points\\center_array.npy\"\n",
    "loaded_array = np.load(file_path.replace(\"\\\\\",\"/\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
